{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARE TO HUMANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to:\n",
    " - remove proper nouns and punctuation from human text ( CONTAINS STOPWORDS BEC USEFUL FOR PHRASES)\n",
    " - analyze phrases for word lists with Q ( shows how many proper nouns and makes removing new phrases resulting from removal of prop. nouns easier ) \n",
    " - and without Q ( for the PMI socre to be accurate)\n",
    " \n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit =pd.read_csv(r'C:\\Users\\Admin\\HC3 EDA\\reddit_filtered_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reddit_human = df_reddit[df_reddit['Labels']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24384\\1010113288.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reddit_human.drop(columns=['Labels'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_reddit_human.drop(columns=['Labels'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Of course! The relevant passage is: \"As to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've actually written a bit about this before....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Incredible answer. This was very well sourced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>That is generally what \"foraging\" implies. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I find it difficult to impose any sort of rigi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>You have fluid in your eyeballs. The added pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>Simply said: There aren't any awkward silences...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>There's this thing called brute forcing. That'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>Pretty much. A small quick dip is all that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>Plastics contain lots of very tiny holes. When...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5145 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Data\n",
       "0     Of course! The relevant passage is: \"As to you...\n",
       "1     I've actually written a bit about this before....\n",
       "3     Incredible answer. This was very well sourced ...\n",
       "5     That is generally what \"foraging\" implies. It ...\n",
       "6     I find it difficult to impose any sort of rigi...\n",
       "...                                                 ...\n",
       "6504  You have fluid in your eyeballs. The added pre...\n",
       "6506  Simply said: There aren't any awkward silences...\n",
       "6507  There's this thing called brute forcing. That'...\n",
       "6509  Pretty much. A small quick dip is all that the...\n",
       "6510  Plastics contain lots of very tiny holes. When...\n",
       "\n",
       "[5145 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean reddit human\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "clean1 = []\n",
    "\n",
    "\n",
    "try:\n",
    "  for sentence in df_reddit_human[\"Data\"]:\n",
    "\n",
    "    # process sentences\n",
    "    cleane = preprocess(sentence)\n",
    "    clean1.append(cleane)\n",
    "\n",
    "except KeyError:\n",
    "  print(\"Column 'Data' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reomve PRP$, ':'and \"''\" replace w q . ALso  '``' and \"''\" \n",
    "good_words =[]\n",
    "for pair in clean1:\n",
    "\n",
    "    for word, tag in pair:\n",
    "        if tag != \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "            good_words.append(word.lower())\n",
    "\n",
    "        elif tag == \"NNP\": \n",
    "            q = \"Q\"\n",
    "            good_words.append(q)\n",
    "\n",
    "        elif tag == \":\":\n",
    "            q = \"T\" \n",
    "            good_words.append(q)\n",
    "\n",
    "        elif tag == \".\":\n",
    "            q = \"T\"\n",
    "            good_words.append(q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without Q\n",
    "# good_words_Qless =[]\n",
    "# for pair in clean1:\n",
    "#     for word, tag in pair:\n",
    "#         if tag!= \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "#             good_words_Qless.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with T and Q\n",
    "# clean_words1 =[]\n",
    "# for word in good_words:\n",
    "#     if word != \"Q\" and word != \"T\":\n",
    "\n",
    "#         lowe= word.lower()\n",
    "#         clean_words1.append(lowe)\n",
    "#     elif word == \"Q\":\n",
    "#         q =\"Q\"\n",
    "#         clean_words1.append(q)\n",
    "#     elif word  == \"T\":\n",
    "#         q = \"T\"\n",
    "#         clean_words1.append(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save no Q reddit human words clean\n",
    "# Qless_df = pd.DataFrame({'Word':clean_words_Qless})\n",
    "# Qless_df.to_csv(\"Q-less Reddit Human Cleanish Words.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reddit human clean to csv\n",
    "red_df = pd.DataFrame({'Words':good_words})\n",
    "red_df.to_csv(\"Q T Reddit Human.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dataframes\n",
    "# df_bigram_r1 = pd.DataFrame({'Phrase':phrase_list_r1 , 'Count':count_list_r1 , 'PMI':pmi_list_r1}) \n",
    "# df_trigram_r2 = pd.DataFrame({'Phrase':phrase_list_r2 , 'Count': count_list_r2 , 'PMI':pmi_list_r2}) \n",
    "# df_quadgram_r3 = pd.DataFrame({'Phrase':phrase_list_r3 , 'Count': count_list_r3 , 'PMI': pmi_list_r3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_essay = pd.read_csv(r\"C:\\Users\\Admin\\student vs gpt essays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6060D28C05B6</td>\n",
       "      <td>Some schools in United States ofter classes fr...</td>\n",
       "      <td>\\nTask: Write a persuasive essay on whether or...</td>\n",
       "      <td>\\nWhen considering the pros and cons of attend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60623DB5DE7A</td>\n",
       "      <td>Four-day work week, a remarkable idea to conse...</td>\n",
       "      <td>\\nTask: Research the advantages and disadvanta...</td>\n",
       "      <td>\\nOne of the primary arguments for implementin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607A39D981DE</td>\n",
       "      <td>Students and their families should consider an...</td>\n",
       "      <td>\\nTask: \\n\\n1. Talk to your parents before tak...</td>\n",
       "      <td>\\nBefore making any decisions about getting in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60ACDFA1609E</td>\n",
       "      <td>Agree you will never grow if something beyond ...</td>\n",
       "      <td>\\nTask: Write an essay discussing the benefits...</td>\n",
       "      <td>\\nRalph Waldo Emerson once said, \"Go confident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60AE13D3F07B</td>\n",
       "      <td>I think our character traits are formed by inf...</td>\n",
       "      <td>\\nTask: Research and discuss how character tra...</td>\n",
       "      <td>\\nHuman character traits are shaped by a wide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>F5FF5E9E553C</td>\n",
       "      <td>On september 2, 2015 Generic_Name was entering...</td>\n",
       "      <td>\\nTask: Research different kinds of medical pr...</td>\n",
       "      <td>\\nBecoming a surgeon requires a great deal of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>F60545D8271E</td>\n",
       "      <td>I think that schools must have a after school ...</td>\n",
       "      <td>\\nTask: Write an essay discussing why schools ...</td>\n",
       "      <td>\\nSchools should offer an after school homewor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>F610B3CBF3DF</td>\n",
       "      <td>Winston Churchill once said \"success consists ...</td>\n",
       "      <td>\\nTask: Write an essay about how having a few ...</td>\n",
       "      <td>\\nItâ€™s human nature to be afraid to make mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>F610C7BCD9EC</td>\n",
       "      <td>Technology seems to be becoming more and more ...</td>\n",
       "      <td>\\nTask: \\n\\nWrite an essay exploring the pros ...</td>\n",
       "      <td>\\nOne of the main debates of 2020 for many stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>F6194DEBEFA7</td>\n",
       "      <td>Teenage is a part of life where everyone wants...</td>\n",
       "      <td>\\nTask: Analyze and explore the benefits of im...</td>\n",
       "      <td>\\nThe implementation of a curfew for teenagers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2421 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "0     6060D28C05B6  Some schools in United States ofter classes fr...   \n",
       "1     60623DB5DE7A  Four-day work week, a remarkable idea to conse...   \n",
       "2     607A39D981DE  Students and their families should consider an...   \n",
       "3     60ACDFA1609E  Agree you will never grow if something beyond ...   \n",
       "4     60AE13D3F07B  I think our character traits are formed by inf...   \n",
       "...            ...                                                ...   \n",
       "2416  F5FF5E9E553C  On september 2, 2015 Generic_Name was entering...   \n",
       "2417  F60545D8271E  I think that schools must have a after school ...   \n",
       "2418  F610B3CBF3DF  Winston Churchill once said \"success consists ...   \n",
       "2419  F610C7BCD9EC  Technology seems to be becoming more and more ...   \n",
       "2420  F6194DEBEFA7  Teenage is a part of life where everyone wants...   \n",
       "\n",
       "                                           instructions  \\\n",
       "0     \\nTask: Write a persuasive essay on whether or...   \n",
       "1     \\nTask: Research the advantages and disadvanta...   \n",
       "2     \\nTask: \\n\\n1. Talk to your parents before tak...   \n",
       "3     \\nTask: Write an essay discussing the benefits...   \n",
       "4     \\nTask: Research and discuss how character tra...   \n",
       "...                                                 ...   \n",
       "2416  \\nTask: Research different kinds of medical pr...   \n",
       "2417  \\nTask: Write an essay discussing why schools ...   \n",
       "2418  \\nTask: Write an essay about how having a few ...   \n",
       "2419  \\nTask: \\n\\nWrite an essay exploring the pros ...   \n",
       "2420  \\nTask: Analyze and explore the benefits of im...   \n",
       "\n",
       "                                            source_text  \n",
       "0     \\nWhen considering the pros and cons of attend...  \n",
       "1     \\nOne of the primary arguments for implementin...  \n",
       "2     \\nBefore making any decisions about getting in...  \n",
       "3     \\nRalph Waldo Emerson once said, \"Go confident...  \n",
       "4     \\nHuman character traits are shaped by a wide ...  \n",
       "...                                                 ...  \n",
       "2416  \\nBecoming a surgeon requires a great deal of ...  \n",
       "2417  \\nSchools should offer an after school homewor...  \n",
       "2418  \\nItâ€™s human nature to be afraid to make mista...  \n",
       "2419  \\nOne of the main debates of 2020 for many stu...  \n",
       "2420  \\nThe implementation of a curfew for teenagers...  \n",
       "\n",
       "[2421 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_essay = df_essay['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean essay \n",
    "import nltk\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "clean2 = []\n",
    "\n",
    "\n",
    "try:\n",
    "  for sentence in human_essay:\n",
    "\n",
    "    # process sentences\n",
    "    cleane = preprocess(sentence)\n",
    "    clean2.append(cleane)\n",
    "\n",
    "except KeyError:\n",
    "  print(\"Column 'Data' not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with T and Q \n",
    "good_words2 =[]\n",
    "for pair in clean2:\n",
    "\n",
    "    for word, tag in pair:\n",
    "        if tag != \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "            good_words2.append(word.lower())\n",
    "\n",
    "        elif tag == \"NNP\": \n",
    "            q = \"Q\"\n",
    "            good_words2.append(q)\n",
    "\n",
    "        elif tag == \":\":\n",
    "            q = \"T\" \n",
    "            good_words2.append(q)\n",
    "\n",
    "        elif tag == \".\":\n",
    "            q = \"T\"\n",
    "            good_words2.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no Q\n",
    "\n",
    "# good_words2_Qless =[]\n",
    "# for pair in clean2:\n",
    "#     for word, tag in pair:\n",
    "#         if tag != \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "#             good_words2_Qless.append(word) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lowercase Qless essay words\n",
    "# clean_words2_Qless =[]\n",
    "# for word in good_words2_Qless:\n",
    "#     if word != \"Q\":\n",
    "\n",
    "#         lowe= word.lower()\n",
    "#         clean_words2_Qless.append(lowe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the essay words to csv\n",
    "ess_df = pd.DataFrame({'Words':good_words2})\n",
    "ess_df.to_csv(\"Q T Essay Human.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the Qless clean words to csv\n",
    "# ess_df_Qx = pd.DataFrame({'Words':clean_words2_Qless})\n",
    "# ess_df_Qx.to_csv(\"Qless Essay Human Words Cleanish .csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3295385806.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 44\u001b[1;36m\u001b[0m\n\u001b[1;33m    count_list_e1_Qx.append(count)  # count for the phrase = bigram\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# # Qless Essay Phrase analysis\n",
    "\n",
    "\n",
    "# # initialize collocation for essays 'e' text QLESS\n",
    "# import nltk\n",
    "# from nltk.collocations import *\n",
    "\n",
    "# # init nltk measures\n",
    "# bigram_measures_e1_Qx = nltk.collocations.BigramAssocMeasures()\n",
    "# trigram_measures_e2_Qx = nltk.collocations.TrigramAssocMeasures()\n",
    "# quadgram_measures_e3_Qx = nltk.collocations.QuadgramAssocMeasures()\n",
    "\n",
    "# # find phrases \n",
    "# finder_e1_Qx = BigramCollocationFinder.from_words(clean_words2_Qless)\n",
    "# finder_e2_Qx = TrigramCollocationFinder.from_words(clean_words2_Qless)\n",
    "# finder_e3_Qx =QuadgramCollocationFinder.from_words(clean_words2_Qless)\n",
    "\n",
    "# # only phrases appearing 10+ times\n",
    "# finder_e1_Qx.apply_freq_filter(10)\n",
    "# finder_e2_Qx.apply_freq_filter(10)\n",
    "# finder_e3_Qx.apply_freq_filter(10)\n",
    "\n",
    "\n",
    "# # define phrase counts\n",
    "# bigram_freq_e1_Qx = finder_e1_Qx.ngram_fd.items()\n",
    "# trigram_freq_e2_Qx = finder_e2_Qx.ngram_fd.items()\n",
    "# quadgram_freq_e3_Qx = finder_e3_Qx.ngram_fd.items()\n",
    "\n",
    "# # define pmis\n",
    "# bigram_pmi_e1_Qx = [i for i in finder_e1_Qx.score_ngrams(bigram_measures_e1_Qx.pmi)]\n",
    "# trigram_pmi_e2_Qx = [i for i in finder_e2_Qx.score_ngrams(trigram_measures_e2_Qx.pmi)]\n",
    "# quadgram_pmi_e3_Qx = [i for i in finder_e3_Qx.score_ngrams(quadgram_measures_e3_Qx.pmi)]\n",
    "\n",
    "# # bigram list creation\n",
    "# pmi_list_e1_Qx =[]\n",
    "# count_list_e1_Qx =  []\n",
    "# phrase_list_e1_Qx =[]\n",
    "\n",
    "# for phrase , pmi in bigram_pmi_e1_Qx:\n",
    "#     for item in bigram_freq_e1_Qx:\n",
    "#         bigram, count = item\n",
    "#         if bigram == phrase:\n",
    "#             pmi_list_e1_Qx.append(pmi) # pmi for the bigram  = phrase\n",
    "            count_list_e1_Qx.append(count)  # count for the phrase = bigram \n",
    "            phrase_list_e1_Qx.append(phrase) # phrase = bigram\n",
    "            \n",
    "\n",
    "#trigram list creation\n",
    "pmi_list_e2_Qx = []\n",
    "count_list_e2_Qx =[]\n",
    "phrase_list_e2_Qx =[]\n",
    "\n",
    "for phrase, pmi in trigram_pmi_e2_Qx:\n",
    "    for item in trigram_freq_e2_Qx:\n",
    "        bigram, count =item\n",
    "        if bigram == phrase:\n",
    "            pmi_list_e2_Qx.append(pmi)\n",
    "            count_list_e2_Qx.append(count)\n",
    "            phrase_list_e2_Qx.append(phrase)\n",
    "\n",
    "# quadgram list creation\n",
    "pmi_list_e3_Qx =[]\n",
    "count_list_e3_Qx =[]\n",
    "phrase_list_e3_Qx =[]\n",
    "\n",
    "for phrase, pmi in quadgram_pmi_e3_Qx:\n",
    "    for item in quadgram_freq_e3_Qx:\n",
    "        quadgram, count =item\n",
    "        if quadgram == phrase:\n",
    "            pmi_list_e3_Qx.append(pmi)\n",
    "            count_list_e3_Qx.append(count)\n",
    "            phrase_list_e3_Qx.append(phrase)\n",
    "\n",
    "# create dataframes\n",
    "df_bigram_e1_Qless = pd.DataFrame({'Phrase':phrase_list_e1_Qx , 'Count':count_list_e1_Qx , 'PMI':pmi_list_e1_Qx}) \n",
    "df_trigram_e2_Qless = pd.DataFrame({'Phrase':phrase_list_e2_Qx , 'Count': count_list_e2_Qx , 'PMI':pmi_list_e2_Qx}) \n",
    "df_quadgram_e3_Qless = pd.DataFrame({'Phrase':phrase_list_e3_Qx , 'Count': count_list_e3_Qx , 'PMI': pmi_list_e3_Qx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH Q\n",
    "\n",
    "# initialize collocation for essays 'e' text\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "# init nltk measures\n",
    "bigram_measures_e1 = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures_e2 = nltk.collocations.TrigramAssocMeasures()\n",
    "quadgram_measures_e3 = nltk.collocations.QuadgramAssocMeasures()\n",
    "\n",
    "# find phrases \n",
    "finder_e1 = BigramCollocationFinder.from_words(good_words2)\n",
    "finder_e2 = TrigramCollocationFinder.from_words(good_words2)\n",
    "finder_e3 =QuadgramCollocationFinder.from_words(good_words2)\n",
    "\n",
    "# only phrases appearing 10+ times\n",
    "finder_e1.apply_freq_filter(10)\n",
    "finder_e2.apply_freq_filter(10)\n",
    "finder_e3.apply_freq_filter(10)\n",
    "\n",
    "\n",
    "# define phrase counts\n",
    "bigram_freq_e1 = finder_e1.ngram_fd.items()\n",
    "trigram_freq_e2 = finder_e2.ngram_fd.items()\n",
    "quadgram_freq_e3 = finder_e3.ngram_fd.items()\n",
    "\n",
    "# define pmis\n",
    "bigram_pmi_e1 = [i for i in finder_e1.score_ngrams(bigram_measures_e1.pmi)]\n",
    "trigram_pmi_e2 = [i for i in finder_e2.score_ngrams(trigram_measures_e2.pmi)]\n",
    "quadgram_pmi_e3 = [i for i in finder_e3.score_ngrams(quadgram_measures_e3.pmi)]\n",
    "\n",
    "# bigram list creation\n",
    "pmi_list_e1 =[]\n",
    "count_list_e1 =  []\n",
    "phrase_list_e1 =[]\n",
    "\n",
    "for phrase , pmi in bigram_pmi_e1:\n",
    "    for item in bigram_freq_e1:\n",
    "        bigram, count = item\n",
    "        if bigram == phrase:\n",
    "            pmi_list_e1.append(pmi) # pmi for the bigram  = phrase\n",
    "            count_list_e1.append(count)  # count for the phrase = bigram \n",
    "            phrase_list_e1.append(phrase) # phrase = bigram\n",
    "            \n",
    "\n",
    "#trigram list creation\n",
    "pmi_list_e2 = []\n",
    "count_list_e2 =[]\n",
    "phrase_list_e2 =[]\n",
    "\n",
    "for phrase, pmi in trigram_pmi_e2:\n",
    "    for item in trigram_freq_e2:\n",
    "        bigram, count =item\n",
    "        if bigram == phrase:\n",
    "            pmi_list_e2.append(pmi)\n",
    "            count_list_e2.append(count)\n",
    "            phrase_list_e2.append(phrase)\n",
    "\n",
    "# quadgram list creation\n",
    "pmi_list_e3 =[]\n",
    "count_list_e3 =[]\n",
    "phrase_list_e3 =[]\n",
    "\n",
    "for phrase, pmi in quadgram_pmi_e3:\n",
    "    for item in quadgram_freq_e3:\n",
    "        quadgram, count =item\n",
    "        if quadgram == phrase:\n",
    "            pmi_list_e3.append(pmi)\n",
    "            count_list_e3.append(count)\n",
    "            phrase_list_e3.append(phrase)\n",
    "\n",
    "# create dataframes\n",
    "df_bigram_e1 = pd.DataFrame({'Phrase':phrase_list_e1 , 'Count':count_list_e1 , 'PMI':pmi_list_e1}) \n",
    "df_trigram_e2 = pd.DataFrame({'Phrase':phrase_list_e2 , 'Count': count_list_e2 , 'PMI':pmi_list_e2}) \n",
    "df_quadgram_e3 = pd.DataFrame({'Phrase':phrase_list_e3 , 'Count': count_list_e3 , 'PMI': pmi_list_e3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes Qless\n",
    "df_bigram_e1_Qless = pd.DataFrame({'Phrase':phrase_list_e1_Qx , 'Count':count_list_e1_Qx , 'PMI':pmi_list_e1_Qx}) \n",
    "df_trigram_e2_Qless = pd.DataFrame({'Phrase':phrase_list_e2_Qx , 'Count': count_list_e2_Qx , 'PMI':pmi_list_e2_Qx}) \n",
    "df_quadgram_e3_Qless = pd.DataFrame({'Phrase':phrase_list_e3_Qx , 'Count': count_list_e3_Qx , 'PMI': pmi_list_e3_Qx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC3 datasets \n",
    "import json\n",
    "\n",
    "with open(r\"C:\\Users\\Admin\\HC3 json file\") as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "# parse the human\n",
    "human_answers = []\n",
    "\n",
    "for row in data['rows']:\n",
    "  human = row['row']['human_answers']\n",
    "  human_answers.append(human)\n",
    "\n",
    "# flatten answers\n",
    "flat_human = [item for sublist in human_answers for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean HC3\n",
    "import nltk \n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "clean3 = []\n",
    "try:\n",
    "  for sentence in flat_human:\n",
    "\n",
    "    # process sentences\n",
    "    cleane = preprocess(sentence)\n",
    "    clean3.append(cleane)\n",
    "\n",
    "except KeyError:\n",
    "  print(\"Column 'Data' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HC3 Qless\n",
    "# good_words3_Qless =[]\n",
    "# for pair in clean3:\n",
    "\n",
    "#     for word, tag in pair:\n",
    "#         if tag != \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "#             good_words3_Qless.append(word)\n",
    "\n",
    "            \n",
    "# clean_words3_Qless =[]\n",
    "# for word in good_words3_Qless:\n",
    "    \n",
    "\n",
    "#     lowe= word.lower()\n",
    "#     clean_words3_Qless.append(lowe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH T FOR PUNCT\n",
    "good_words3 =[]\n",
    "for pair in clean3:\n",
    "\n",
    "    for word, tag in pair:\n",
    "        if tag != \"NNP\" and tag != \":\" and tag != \"''\" and tag != \"``\" and tag != \".\":\n",
    "            good_words3.append(word.lower())\n",
    "\n",
    "        elif tag == \"NNP\": \n",
    "            q = \"Q\"\n",
    "            good_words3.append(q)\n",
    "\n",
    "        elif tag == \":\":\n",
    "            q = \"T\" \n",
    "            good_words3.append(q)\n",
    "\n",
    "        elif tag == \".\":\n",
    "            q = \"T\"\n",
    "            good_words3.append(q)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the HC3 words to csv\n",
    "import pandas as pd\n",
    "hc3_df = pd.DataFrame({'Words':good_words3})\n",
    "hc3_df.to_csv(\"Q T HC3 Human.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save QLess HC3\n",
    "# # save the HC3 words to csv\n",
    "# hc3_df_Qx = pd.DataFrame({'Words':clean_words3_Qless})\n",
    "# hc3_df_Qx.to_csv(\"HC3 Human Clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "> find number  of proper nouns in each of the following: human-essay = 10747 | human-HC3 = 1201 | and human-reddit = 44661  | 56,609 |||\n",
    ">> count original number of words in each uncleaned corpus | human-HC3 = 35969  | human-reddit = 909307 | human-essay = 1143024   |||  = 2,088,300\n",
    ">>> count number of T's = periods  | in human-essays= 45613 |  human-HC3= 2007 |  human reddit= 40716  ||| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mean_sentence_length_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mean_sentence_length_function\n",
    "from mean_sentence_length_function import *\n",
    "\n",
    "# get number of T = periods in each text\n",
    "ess_Ts = ess_df.value_counts().get('T',0)\n",
    "HC_Ts = hc3_df.value_counts().get('T',0)\n",
    "red_Ts = red_df.value_counts().get('T',0)\n",
    "\n",
    "HC_mean_sent = average_sent_length(hc3_df,HC_Ts)\n",
    "ess_mean_sent = average_sent_length(ess_df,ess_Ts)\n",
    "red_mean_sent = average_sent_length(red_df,red_Ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.92177379172895\n",
      "24.05917172735843\n",
      "21.332915807053737\n"
     ]
    }
   ],
   "source": [
    "print(HC_mean_sent)\n",
    "print(ess_mean_sent)\n",
    "print(red_mean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.771287108713704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AGGREGATE AVERAGE\n",
    "(16.92177379172895 +24.05917172735843 + 21.332915807053737)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Average human sentence length is 20.771287108713704 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Words\n",
       "T        2007\n",
       "the      1601\n",
       ",        1414\n",
       "Q        1201\n",
       "to        972\n",
       "a         869\n",
       "and       804\n",
       "of        689\n",
       "is        551\n",
       "it        550\n",
       "that      498\n",
       "in        460\n",
       "you       360\n",
       "are       304\n",
       "for       294\n",
       "'s        293\n",
       "they      284\n",
       ")         231\n",
       "be        227\n",
       "or        218\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hc3_df.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_df.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Words\n",
       "the      46435\n",
       "Q        44661\n",
       "T        40716\n",
       ",        39806\n",
       "of       23140\n",
       "to       21875\n",
       "and      19646\n",
       "a        18832\n",
       "in       15232\n",
       "that     12063\n",
       "is       11396\n",
       "it       10238\n",
       "you       6907\n",
       "for       6697\n",
       ")         6187\n",
       "this      6075\n",
       "as        6062\n",
       "(         6055\n",
       "i         6025\n",
       "was       5707\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_df.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Now count number of words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(string):\n",
    "    st1 = string.strip()\n",
    "    count = 1\n",
    "    for i in st1:\n",
    "        if i == \" \":\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(ess_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35969"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(hc3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(red_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Qless SAME LIST NAMES DIFF Dataframe\n",
    "# # initialize collocation for HC3 'h' text\n",
    "# import nltk\n",
    "# from nltk.collocations import *\n",
    "\n",
    "# # init nltk measures\n",
    "# bigram_measures_h1_Qx = nltk.collocations.BigramAssocMeasures()\n",
    "# trigram_measures_h2_Qx = nltk.collocations.TrigramAssocMeasures()\n",
    "# quadgram_measures_h3_Qx = nltk.collocations.QuadgramAssocMeasures()\n",
    "\n",
    "# # find phrases \n",
    "# finder_h1_Qx = BigramCollocationFinder.from_words(clean_words3_Qless)\n",
    "# finder_h2_Qx= TrigramCollocationFinder.from_words(clean_words3_Qless)\n",
    "# finder_h3_Qx =QuadgramCollocationFinder.from_words(clean_words3_Qless)\n",
    "\n",
    "# # only phrases appearing 10+ times\n",
    "# finder_h1_Qx.apply_freq_filter(10)\n",
    "# finder_h2_Qx.apply_freq_filter(10)\n",
    "# finder_h3_Qx.apply_freq_filter(10)\n",
    "\n",
    "\n",
    "# # define phrase counts\n",
    "# bigram_freq_h1_Qx = finder_h1_Qx.ngram_fd.items()\n",
    "# trigram_freq_h2_Qx = finder_h2_Qx.ngram_fd.items()\n",
    "# quadgram_freq_h3_Qx = finder_h3_Qx.ngram_fd.items()\n",
    "\n",
    "# # define pmis\n",
    "# bigram_pmi_h1_Qx = [i for i in finder_h1_Qx.score_ngrams(bigram_measures_h1_Qx.pmi)]\n",
    "# trigram_pmi_h2_Qx = [i for i in finder_h2_Qx.score_ngrams(trigram_measures_h2_Qx.pmi)]\n",
    "# quadgram_pmi_h3_Qx = [i for i in finder_h3_Qx.score_ngrams(quadgram_measures_h3_Qx.pmi)]\n",
    "\n",
    "# # bigram list creation\n",
    "# pmi_list_h1_Qx =[]\n",
    "# count_list_h1_Qx =  []\n",
    "# phrase_list_h1_Qx =[]\n",
    "\n",
    "# for phrase , pmi in bigram_pmi_h1_Qx:\n",
    "#     for item in bigram_freq_h1_Qx:\n",
    "#         bigram, count = item\n",
    "#         if bigram == phrase:\n",
    "#             pmi_list_h1_Qx.append(pmi) # pmi for the bigram  = phrase\n",
    "#             count_list_h1_Qx.append(count)  # count for the phrase = bigram \n",
    "#             phrase_list_h1_Qx.append(phrase) # phrase = bigram\n",
    "            \n",
    "\n",
    "# #trigram list creation\n",
    "# pmi_list_h2_Qx = []\n",
    "# count_list_h2_Qx =[]\n",
    "# phrase_list_h2_Qx =[]\n",
    "\n",
    "# for phrase, pmi in trigram_pmi_h2_Qx:\n",
    "#     for item in trigram_freq_h2_Qx:\n",
    "#         bigram, count =item\n",
    "#         if bigram == phrase:\n",
    "#             pmi_list_h2_Qx.append(pmi)\n",
    "#             count_list_h2_Qx.append(count)\n",
    "#             phrase_list_h2_Qx.append(phrase)\n",
    "\n",
    "# # quadgram list creation\n",
    "# pmi_list_h3_Qx =[]\n",
    "# count_list_h3_Qx =[]\n",
    "# phrase_list_h3_Qx =[]\n",
    "\n",
    "# for phrase, pmi in quadgram_pmi_h3_Qx:\n",
    "#     for item in quadgram_freq_h3_Qx:\n",
    "#         quadgram, count =item\n",
    "#         if quadgram == phrase:\n",
    "#             pmi_list_h3_Qx.append(pmi)\n",
    "#             count_list_h3_Qx.append(count)\n",
    "#             phrase_list_h3_Qx.append(phrase)\n",
    "\n",
    "# # create dataframes\n",
    "# df_bigram_h1_Qless = pd.DataFrame({'Phrase':phrase_list_h1_Qx , 'Count':count_list_h1_Qx , 'PMI':pmi_list_h1_Qx}) \n",
    "# df_trigram_h2_Qless = pd.DataFrame({'Phrase':phrase_list_h2_Qx , 'Count': count_list_h2_Qx , 'PMI':pmi_list_h2_Qx}) \n",
    "# df_quadgram_h3_Qless = pd.DataFrame({'Phrase':phrase_list_h3_Qx , 'Count': count_list_h3_Qx , 'PMI': pmi_list_h3_Qx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: JOIN ALL LISTS INTO ONE AND CONVERT TO STRING\n",
    "combo_list = good_words3 + good_words + good_words2\n",
    "combo_string = ' '.join(combo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_list = pd.Series(combo_list)\n",
    "HUMAN_list.to_csv('QT HUMAN Words List plain.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: START BI-TIR-QUAD EVAL; INSTANTIATE\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "# BI\n",
    "finder = BigramCollocationFinder.from_words(combo_string.split())\n",
    "finder.apply_freq_filter(10)\n",
    "#TRI\n",
    "finder2 = TrigramCollocationFinder.from_words(combo_string.split())\n",
    "finder2.apply_freq_filter(10)\n",
    "\n",
    "# QUAD\n",
    "quadgram_measures = nltk.collocations.QuadgramAssocMeasures()\n",
    "finder3 =QuadgramCollocationFinder.from_words(combo_string.split())\n",
    "finder3.apply_freq_filter(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: FIND PMI AND COUNT FOR EACH PHRASE\n",
    "\n",
    "#pmi\n",
    "bigram_pmi = [i for i in finder.score_ngrams(bigram_measures.pmi)]\n",
    "trigram_pmi = [i for i in finder2.score_ngrams(trigram_measures.pmi)]\n",
    "quadgram_pmi = [i for i in finder3.score_ngrams(quadgram_measures.pmi)]\n",
    "# count\n",
    "bigram_freq1 = finder.ngram_fd.items()\n",
    "trigram_freq1 = finder2.ngram_fd.items()\n",
    "quadgram_freq1 = finder3.ngram_fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4a: bigrams\n",
    "pmi3_list =[]\n",
    "count3_list =[]\n",
    "phrase3_list =[]\n",
    "for phrase, pmi in bigram_pmi:\n",
    "    for item in bigram_freq1:\n",
    "        quadgram,count = item\n",
    "        if quadgram == phrase:\n",
    "            pmi3_list.append(pmi)\n",
    "            count3_list.append(count)\n",
    "            phrase3_list.append(phrase)\n",
    "\n",
    "                # create dataframe\n",
    "            df_bigrams = pd.DataFrame({'Phrase':phrase3_list,'PMI':pmi3_list,'Count':count3_list})\n",
    " \n",
    "# remove parentheses and join words into one string \n",
    "phrases_clean =[]\n",
    "for word in df_bigrams['Phrase']:\n",
    "    brack = ' '.join(word)\n",
    "    phrases_clean.append(brack)\n",
    "\n",
    "# now replace in df\n",
    "df_bigrams['Phrase'] = phrases_clean\n",
    "\n",
    "df_bigrams.to_csv('QT HUMAN Bigrams V2.csv', index ='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4b: trigrams\n",
    "pmi3_list =[]\n",
    "count3_list =[]\n",
    "phrase3_list =[]\n",
    "for phrase, pmi in trigram_pmi:\n",
    "    for item in trigram_freq1:\n",
    "        quadgram,count = item\n",
    "        if quadgram == phrase:\n",
    "            pmi3_list.append(pmi)\n",
    "            count3_list.append(count)\n",
    "            phrase3_list.append(phrase)\n",
    "\n",
    "                # create dataframe\n",
    "            df_trigrams = pd.DataFrame({'Phrase':phrase3_list,'PMI':pmi3_list,'Count':count3_list})\n",
    "# remove parentheses and join words into one string \n",
    "phrases_clean =[]\n",
    "for word in df_trigrams['Phrase']:\n",
    "    brack = ' '.join(word)\n",
    "    phrases_clean.append(brack)\n",
    "\n",
    "# now replace in df\n",
    "df_trigrams['Phrase'] = phrases_clean\n",
    "\n",
    "df_trigrams.to_csv('QT HUMAN Trigrams V2.csv', index ='False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4c: quadgrams\n",
    "pmi3_list =[]\n",
    "count3_list =[]\n",
    "phrase3_list =[]\n",
    "for phrase, pmi in quadgram_pmi:\n",
    "    for item in quadgram_freq1:\n",
    "        quadgram,count = item\n",
    "        if quadgram == phrase:\n",
    "            pmi3_list.append(pmi)\n",
    "            count3_list.append(count)\n",
    "            phrase3_list.append(phrase)\n",
    "\n",
    "                # create dataframe\n",
    "            df_quadgrams = pd.DataFrame({'Phrase':phrase3_list,'PMI':pmi3_list,'Count':count3_list})\n",
    "    # return df\n",
    "phrases_clean =[]\n",
    "for word in df_quadgrams['Phrase']:\n",
    "    brack = ' '.join(word)\n",
    "    phrases_clean.append(brack)\n",
    "\n",
    "# now replace in df\n",
    "df_quadgrams['Phrase'] = phrases_clean\n",
    "# save\n",
    "df_quadgrams.to_csv('QT HUMAN Quadgrams V2.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dfs (9) to evaluate most common and highest pmi across all human and phrase sizes\n",
    "\n",
    "merged_df = pd.concat([df_bigram_r1,df_bigram_e1,df_bigram_h1,df_trigram_e2,df_trigram_r2,df_trigram_h2,df_quadgram_r3,df_quadgram_h3,df_quadgram_e3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all QLESSS dfs (9) to evaluate most common and highest pmi across all human and phrase sizes\n",
    "\n",
    "merged_df_Qx = pd.concat([df_bigram_r1_Qx,df_bigram_e1_Qless,df_bigram_h1_Qless,df_trigram_e2_Qless,df_trigram_r2_Qx,df_trigram_h2_Qless,df_quadgram_r3_Qx,df_quadgram_h3_Qless,df_quadgram_e3_Qless])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(vice, versa)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.545247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(gon, na)</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.330234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(belly, dancing)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.745272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(et, al)</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.691517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(voter, turnout)</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.633836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>(to, the, school, ,)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>(,, ,, ,, and)</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.816196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>(you, ,, and, you)</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.663686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>(,, and, to, be)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.521938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>(to, be, ,, and)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.521938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41470 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Phrase  Count        PMI\n",
       "0            (vice, versa)   13.0  15.545247\n",
       "1                (gon, na)   17.0  15.330234\n",
       "2         (belly, dancing)   10.0  14.745272\n",
       "3                 (et, al)   36.0  13.691517\n",
       "4         (voter, turnout)   11.0  13.633836\n",
       "...                    ...    ...        ...\n",
       "3289  (to, the, school, ,)   10.0   4.936693\n",
       "3290        (,, ,, ,, and)   27.0   4.816196\n",
       "3291    (you, ,, and, you)   12.0   4.663686\n",
       "3292      (,, and, to, be)   10.0   4.521938\n",
       "3293      (to, be, ,, and)   10.0   4.521938\n",
       "\n",
       "[41470 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df_Qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_phrase_Qx =[]\n",
    "for phrase in merged_df_Qx['Phrase']:\n",
    "    clean = ' '.join(phrase)\n",
    "    good_phrase_Qx.append(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_Qx['Phrase'] = good_phrase_Qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vice versa</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.545247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gon na</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.330234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belly dancing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.745272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et al</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.691517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voter turnout</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.633836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>to the school ,</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.936693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>, , , and</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.816196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>you , and you</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.663686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>, and to be</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.521938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>to be , and</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.521938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41470 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Phrase  Count        PMI\n",
       "0          vice versa   13.0  15.545247\n",
       "1              gon na   17.0  15.330234\n",
       "2       belly dancing   10.0  14.745272\n",
       "3               et al   36.0  13.691517\n",
       "4       voter turnout   11.0  13.633836\n",
       "...               ...    ...        ...\n",
       "3289  to the school ,   10.0   4.936693\n",
       "3290        , , , and   27.0   4.816196\n",
       "3291    you , and you   12.0   4.663686\n",
       "3292      , and to be   10.0   4.521938\n",
       "3293      to be , and   10.0   4.521938\n",
       "\n",
       "[41470 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df_Qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Qx to csvc\n",
    "merged_df_Qx.to_csv('NO Q BI TRI QUAD HUMAN GRAMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('Q BI TRI QUAD HUMAN GRAMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows =len(df_bigram_e1)+len(df_bigram_r1)+len(df_bigram_h1)+len(df_quadgram_h3)+len(df_quadgram_e3)+len(df_quadgram_r3) +len(df_trigram_e2)+len(df_trigram_r2)+len(df_trigram_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(vice, versa)</td>\n",
       "      <td>13</td>\n",
       "      <td>15.687493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(gon, na)</td>\n",
       "      <td>17</td>\n",
       "      <td>15.472480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(belly, dancing)</td>\n",
       "      <td>10</td>\n",
       "      <td>14.887517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(et, al)</td>\n",
       "      <td>36</td>\n",
       "      <td>13.833762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(voter, turnout)</td>\n",
       "      <td>11</td>\n",
       "      <td>13.776081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>(and, Q, Q, Q)</td>\n",
       "      <td>15</td>\n",
       "      <td>2.059183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>(,, Q, Q, Q)</td>\n",
       "      <td>16</td>\n",
       "      <td>1.953025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>(Q, the, Q, Q)</td>\n",
       "      <td>12</td>\n",
       "      <td>1.498807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>(Q, Q, Q, and)</td>\n",
       "      <td>10</td>\n",
       "      <td>1.474220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>(to, Q, Q, Q)</td>\n",
       "      <td>14</td>\n",
       "      <td>1.387394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46654 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Phrase  Count        PMI\n",
       "0        (vice, versa)     13  15.687493\n",
       "1            (gon, na)     17  15.472480\n",
       "2     (belly, dancing)     10  14.887517\n",
       "3             (et, al)     36  13.833762\n",
       "4     (voter, turnout)     11  13.776081\n",
       "...                ...    ...        ...\n",
       "4068    (and, Q, Q, Q)     15   2.059183\n",
       "4069      (,, Q, Q, Q)     16   1.953025\n",
       "4070    (Q, the, Q, Q)     12   1.498807\n",
       "4071    (Q, Q, Q, and)     10   1.474220\n",
       "4072     (to, Q, Q, Q)     14   1.387394\n",
       "\n",
       "[46654 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('bi tri quad human metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_phrase =[]\n",
    "for phrase in merged_df['Phrase']:\n",
    "    clean = ' '.join(phrase)\n",
    "    good_phrase.append(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Phrase'] = good_phrase\n",
    "# run to_csv cell block above again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now explore\n",
    "merged_df = merged_df.sort_values('PMI',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the firs two rows which are context specific\n",
    "merged_df = merged_df.drop(axis=0,labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>of ,</td>\n",
       "      <td>30</td>\n",
       "      <td>-5.077501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>to is</td>\n",
       "      <td>19</td>\n",
       "      <td>-5.103449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>to can</td>\n",
       "      <td>13</td>\n",
       "      <td>-5.132106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>they to</td>\n",
       "      <td>19</td>\n",
       "      <td>-5.138809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14336</th>\n",
       "      <td>the they</td>\n",
       "      <td>15</td>\n",
       "      <td>-5.146041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>the a</td>\n",
       "      <td>20</td>\n",
       "      <td>-5.163714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>and and</td>\n",
       "      <td>22</td>\n",
       "      <td>-5.163801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>can the</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.176812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>to to</td>\n",
       "      <td>44</td>\n",
       "      <td>-5.308308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>the that</td>\n",
       "      <td>15</td>\n",
       "      <td>-5.310682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>a a</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.411723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>the is</td>\n",
       "      <td>12</td>\n",
       "      <td>-5.432608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344</th>\n",
       "      <td>of to</td>\n",
       "      <td>12</td>\n",
       "      <td>-5.438868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>i ,</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.443890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14346</th>\n",
       "      <td>to for</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.484278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>they and</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.492556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>a the</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.026210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>to in</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>they Q</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.401111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>the the</td>\n",
       "      <td>25</td>\n",
       "      <td>-6.567586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Phrase  Count       PMI\n",
       "9622       of ,     30 -5.077501\n",
       "14333     to is     19 -5.103449\n",
       "14334    to can     13 -5.132106\n",
       "14335   they to     19 -5.138809\n",
       "14336  the they     15 -5.146041\n",
       "14337     the a     20 -5.163714\n",
       "14338   and and     22 -5.163801\n",
       "14339   can the     10 -5.176812\n",
       "14340     to to     44 -5.308308\n",
       "14341  the that     15 -5.310682\n",
       "14342       a a     11 -5.411723\n",
       "14343    the is     12 -5.432608\n",
       "14344     of to     12 -5.438868\n",
       "14345       i ,     11 -5.443890\n",
       "14346    to for     11 -5.484278\n",
       "14347  they and     10 -5.492556\n",
       "14348     a the     11 -6.026210\n",
       "14349     to in     10 -6.165500\n",
       "14350    they Q     10 -6.401111\n",
       "9623    the the     25 -6.567586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quadgrams have high pmi and bigrams have negative ; i.e. higher joint prob than indiv vs. higher indiv. porb than joint prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>formed by influences beyond</td>\n",
       "      <td>20</td>\n",
       "      <td>32.803633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seek guidance from experts</td>\n",
       "      <td>45</td>\n",
       "      <td>32.645959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better familiarize yourself with</td>\n",
       "      <td>53</td>\n",
       "      <td>31.547293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retain information as easily</td>\n",
       "      <td>10</td>\n",
       "      <td>31.281380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>influences beyond our control</td>\n",
       "      <td>25</td>\n",
       "      <td>31.198736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>providing follow up information</td>\n",
       "      <td>11</td>\n",
       "      <td>31.168131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>schools offer distance learning</td>\n",
       "      <td>31</td>\n",
       "      <td>30.845589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>further derail this thread</td>\n",
       "      <td>10</td>\n",
       "      <td>30.669236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>provide users with in-depth</td>\n",
       "      <td>10</td>\n",
       "      <td>30.572888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>character formed by influences</td>\n",
       "      <td>10</td>\n",
       "      <td>30.426663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tasks without having contact</td>\n",
       "      <td>17</td>\n",
       "      <td>30.330385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>small acts of kindness</td>\n",
       "      <td>19</td>\n",
       "      <td>30.186502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>someone capable of engaging</td>\n",
       "      <td>15</td>\n",
       "      <td>29.955864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seeking multiple opinions can</td>\n",
       "      <td>21</td>\n",
       "      <td>29.884351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>setting our aim too</td>\n",
       "      <td>21</td>\n",
       "      <td>29.786959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>consisting of ten hours</td>\n",
       "      <td>19</td>\n",
       "      <td>29.713366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>play games without speaking</td>\n",
       "      <td>10</td>\n",
       "      <td>29.641778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>limitation of human contact</td>\n",
       "      <td>29</td>\n",
       "      <td>29.595761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>informed response from someone</td>\n",
       "      <td>15</td>\n",
       "      <td>29.582138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>does inactivity also serve</td>\n",
       "      <td>19</td>\n",
       "      <td>29.518296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Phrase  Count        PMI\n",
       "2        formed by influences beyond     20  32.803633\n",
       "3         seek guidance from experts     45  32.645959\n",
       "2   better familiarize yourself with     53  31.547293\n",
       "4       retain information as easily     10  31.281380\n",
       "5      influences beyond our control     25  31.198736\n",
       "3    providing follow up information     11  31.168131\n",
       "6    schools offer distance learning     31  30.845589\n",
       "4         further derail this thread     10  30.669236\n",
       "5        provide users with in-depth     10  30.572888\n",
       "7     character formed by influences     10  30.426663\n",
       "8       tasks without having contact     17  30.330385\n",
       "9             small acts of kindness     19  30.186502\n",
       "6        someone capable of engaging     15  29.955864\n",
       "10     seeking multiple opinions can     21  29.884351\n",
       "11               setting our aim too     21  29.786959\n",
       "12           consisting of ten hours     19  29.713366\n",
       "13       play games without speaking     10  29.641778\n",
       "14       limitation of human contact     29  29.595761\n",
       "7     informed response from someone     15  29.582138\n",
       "15        does inactivity also serve     19  29.518296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Count</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>Q Q</td>\n",
       "      <td>19575</td>\n",
       "      <td>1.288013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>the Q</td>\n",
       "      <td>6517</td>\n",
       "      <td>0.579915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>Q Q</td>\n",
       "      <td>6170</td>\n",
       "      <td>1.150711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>Q Q Q</td>\n",
       "      <td>5782</td>\n",
       "      <td>2.941489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>of the</td>\n",
       "      <td>5533</td>\n",
       "      <td>2.227228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>, the best</td>\n",
       "      <td>10</td>\n",
       "      <td>3.977374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>young age it</td>\n",
       "      <td>10</td>\n",
       "      <td>11.349398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>be any</td>\n",
       "      <td>10</td>\n",
       "      <td>0.851580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10317</th>\n",
       "      <td>reason would</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>in everything Q</td>\n",
       "      <td>10</td>\n",
       "      <td>3.910095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46636 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Phrase  Count        PMI\n",
       "6599               Q Q  19575   1.288013\n",
       "7726             the Q   6517   0.579915\n",
       "9495               Q Q   6170   1.150711\n",
       "3690             Q Q Q   5782   2.941489\n",
       "4917            of the   5533   2.227228\n",
       "...                ...    ...        ...\n",
       "3298        , the best     10   3.977374\n",
       "1012      young age it     10  11.349398\n",
       "7320            be any     10   0.851580\n",
       "10317     reason would     10   0.852112\n",
       "9735   in everything Q     10   3.910095\n",
       "\n",
       "[46636 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df.sort_values('Count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top count is significant becausr shows humans use proper nouns a lot 1 , disregard pMI . Maybe add Q's to chatgpt to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi and Tri Gram notebook conatins code that evaluates chatgpt phrases with and without Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the prob with putting Q in place of punct and proper nouns is that pmi is not accurate (i.e. prob of Q )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
